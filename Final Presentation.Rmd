---
title: "Fitting and Model Checking a Linear Preferential Attachment Model for Directed Graphs"
author: | 
  | Ting-Yuan Kuo
  | 26th April, 2018
output: beamer_presentation
header-includes:
  - \widowpenalties 1 150
bibliography: MA703.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Linear Preferential Attachment (Linear PA)

- Motivated to provide an explaination to the phenomenom of scale-free networks ($\iff$ power law), first proposed by @Barabasi1999a
- Belongs to the class Network Growth Models 
- Will generate "rich-get-richer" effect 
- Gets a power law asympototically for its degree distribution.

## Canonical Linear PA Model: Barabasi-Albert (1999)

- A random growth model for undirected, unweighted graphs
- Let there be an initial graph, $G(t_0)$, with node size $m_0$
- Add a node at each time-step $t$ to $G(t)$ and connect the newly added node to $m (\leq m_0)$ nodes present in $G(t-1)$ by
$$\mathbb{P}[\text{choose } v \in G(t-1)] = \frac{k_v}{\sum_j k_j}$$
where $k_v$ is the degree of node $v \in G(t-1)$

- Linear in the sense that 
$$\frac{{k_v}^\alpha}{\sum_j {k_j}^\alpha}, \ \alpha = 1 $$

## Power Law 

- @Bollobas2001 shows that as $t \to \infty$
$$f_d \propto d^{-\gamma}, \ \gamma = 3$$
where $f_d$ is the number of nodes with degree $d$, iff $\alpha =1$

- In the limit $f_d$ has a power law exponent of 3 
    - If $\alpha < 1$, we get stretched exponential; if $\alpha > 1$, a single node connects to nearly all other nodes [@Krapivsky2000].

- Likely too simple for empirical data, so I will fit another linear PA model for directed graphs

## Goal

**1) To fit a linear PA model for directed graphs based only on a snap-shot of the graph and 2) check whether the model is a good fit in terms of the degree distribution **

- Important since we often cannot observe the full history of the graph
- Most empirical work on testing for power law of the distribution rely on directly testing the resulting degree distribution
    - Hard to fit fat-tailed distributions [@Broido2018]
    - Hard to distinguish between fat-tailed distributions, more rigorous method is by likelihood ratio tests, but seldom done 

- By directly fitting the model, we can do predictive checking and provide another tool kit to test the power law hypothesis 

## The Linear PA Model for Directed Graphs

Notation: Let $D_{in}^{(n)}(u) \text{ and } D_{out}^{(n)}(u)$ denote the in- and out-degree of node $u$ in $G(n)$, respectively. 

1. At each time-step $n$, toss an unfair three-sided coin $J_n$ with $\Omega = \{1, 2, 3\}$ and the mass function, $\mathbb{P}(J_n = 1) = \alpha, \ \mathbb{P}(J_n = 2) = \beta, \ \mathbb{P}(J_n = 3) = \gamma$. Assume $0 < \alpha, \ \beta,\ \gamma < 1$. 

2. If $J_n = 1$ ($\alpha$-scheme): Add a new node, $v$, to $G(n-1)$ and an edge $(v, w)$ leading from $v$ to a previously existing $w \in V(n-1)$. Choose $w$ by, 
$$
\mathbb{P}[\text{ choose } w \in V(n-1)] = \frac{ D_{in}^{(n-1)}(w) + \delta_{in} }{n - 1 + \delta_{in}N(n-1)}
$$
That is choose $w$ with the probability proportional to its in-degree and corrected by a bias parameter $\delta_{in}$

## Cont. 

3.  If $J_n = 2$ ($\beta$-scheme): Add a directed edge $(v, w)$ to $E(n-1)$ where $v, w \in V(n-1)$ (no new node is added). Choose $(v, w)$ as such, 
$$
\mathbb{P}[\text{choose } (v, w)] = \Big(\frac{ D_{in}^{(n-1)}(v) + \delta_{in} }{n - 1 + \delta_{in}N(n-1)} \Big) \Big( \frac{ D_{out}^{(n-1)}(w) + \delta_{out} }{n - 1 + \delta_{out}N(n-1)}\Big)
$$

4. If $J_n = 3$ ($\gamma$-scheme): Add a new node $w$ to $G(n-1)$ and an edge (v, w) leading from an existing node $v$ to $w$ with the probability, 
$$
\mathbb{P}[\text{ choose } v \in V(n-1)] = \frac{ D_{out}^{(n-1)}(v) + \delta_{out} }{n - 1 + \delta_{out}N(n-1)}
$$

- Note: this is a 5 parameter model with $\theta = (\alpha, \beta, \gamma, \delta_{in}, \delta_{out})$

## Power Law for this model

- @Bollobas2003 showed that for this model the in- and out-degree distribution also has power law

Roughly, let $p_i$ and $q_i$ be the in and out degree distribution respectively ($i$ denotes the degree count), then in the limit, 

$$
p_i \propto i^{\kappa_{in}},  \ \ \text{    if } \alpha \delta_{in} + \gamma > 0 
$$
$$
q_i \propto i^{\kappa_{out}},  \ \ \text{    if } \gamma \delta_{out} + \alpha > 0
$$
Where,
$$
\kappa_{in} = 1 + \frac{1+ \delta_{in}(\alpha + \gamma)}{\alpha + \beta} 
$$
$$
\kappa_{out} = 1 + \frac{1+ \delta_{out}(\alpha + \gamma)}{\beta + \gamma}
$$

## Estimation, Inference, and Simulation

- Most work on estimating network growth models rely on having the full history the graph, $\{ G(t)\}_{t = t_0}^{m}$. But in most practical circumstances we can only observe some snap-shot $G(t^*)$

- @Wan2017 proposes an approximate MLE estimator $\tilde{\theta}$ for $\theta$ that is strongly consistent (i.e. $\tilde{\theta} \overset{a.s.}{\to \theta}$ as $n\to \infty$). See p.13-14 of their paper for the algorithm. They also came up with a fast simulation algorithm. 

- No formal inference procedure, instead suggested an ad-hoc boostrapping procedure to compute the sample variance of $\tilde{\theta}$ based on repeated indepedent simulations. Will not be doing this due to computational constraints. 

## Picture

```{r, echo=FALSE, message=FALSE, fig.align="center",fig.height=5.5, fig.width=7, fig.cap = "Fruchterman Reingold layout of the Linear PA Model with 1000 edges"}
library(igraph)
load("/Users/MacUser/Desktop/Network/Final Project/SampleSim.RData")
plot(sample_g, layout=l, vertex.size = 0.4*degree(sample_g, mode = "total"), 
      vertex.label = NA, vertex.shape = c("circle"), 
      edge.width = 0.5, edge.arrow.size=0.05, edge.arrow.width=0.5,
      vertex.color=c("blue"), vertex.border = c("blue"))

```


## Illustration: Bitcoin Network Data

- Downloaded from the Stanford SNAP website.
\vspace{12pt}
- Directed and temporal. Has 35,592 edges, 5881 nodes. 
\vspace{12pt}
- Transaction data: edge $(v, w)$ means $v$ sold to $w$. $(w, v)$ for vice versa 
\vspace{12pt}
- I will pool together all data to pretend that we only have one snap-shot (i.e. only has the final adj. matrix and do not know the true edge/node permutation)


## Estimation and Simulation
- Fitting the network, we get

$$
\tilde{\theta} = (\tilde{\alpha}, \tilde{\beta}, \tilde{\gamma}, \tilde{\delta}_{in},  \tilde{\delta}_{out} ) = (0.0029, \ 0.8348, \ 0.1623, \ 1.4834, \ 3.9572)
$$

$$ 
\implies
\tilde{\kappa}^{in} = 2.4862, \ \ \ \ 
\tilde{\kappa}^{out} = 2.6588
$$


- Then use $\tilde{\theta}$ to simulate a network, $G(t)_{sim}$, with 35,592 edges (matching data) - we get 5873 nodes! (recall real network has 5881 nodes)

## Sanity Check for the Estimates

- $\tilde{\theta}_{sim}$ of $G(t)_{sim}$ is (0.0033, 0.8350, 0.1617, 1.6574, 4.1046)
    
- Fitting the simulated degree distribution using a power law MLE method proposed by @Clauset2007,
$$\hat{\kappa}^{in}_{sim} = 2.4140 \ \ \ \ \hat{\kappa}^{out}_{sim} = 2.3887$$
with 95% CI, $\big(2.2131, \ 2.6149 \big)$ and $\big(2.1758, \  2.6016\big)$
    - We know for sure, $\kappa^{in}_{sim} = 2.4862$ and $\kappa^{out}_{sim} = 2.6588$
- In terms of goodness of fit, we can accept the null hypothesis that both the in and out-degree distribution of the simulated network follows power law, $p = 0.14$ and $p = 0.15$, respectively


## Back to Bitcoin Data

- Recall for the Bitcoin network, our parametric model says that 
$$\tilde{\kappa}^{in} = 2.4862 \ \ \ \ \  \tilde{\kappa}^{out} = 2.6588$$

- On the other hand, by the @Clauset2007 power law MLE method on the empirical distribution
$$\hat{\kappa}^{in} = 2.2708 \ \ \ \ \ \hat{\kappa}^{out} = 2.0594$$
with 95% CI, $\big(2.1141, \ 2.4275 \big)$ and $\big(1.9847, \  2.1341\big)$. Goodness of fit says we reject the null hypothesis that the in and out-degree comes from power law, $p=0.02$ and $p < 10^{-6}$. 

$\implies$ Some disagreement. By direct MLE estimation of the degree distributions, real data has much fatter tails
    
## Predictive Checking: Degree Distribution

```{r, echo=FALSE, warning=FALSE, message = FALSE, fig.align="center",fig.height=3, fig.width=4, fig.cap = "Degree Distribution of the Real and Simulated Network"}
source("/Users/MacUser/Desktop/Network/Final Project/Functions.R")
load("/Users/MacUser/Desktop/Network/Final Project/Bit.RData")

par(mfrow=c(1,2)) 
par(mar = c(3,2,1,2))
PlotDegree(graph1 = sim_bit_g, graph2 = bit_graph, direction = "in")
PlotDegree(graph1 = sim_bit_g, graph2 = bit_graph, direction = "out")
```

## Predictive Checking: Kolmogorov-Sminrov (KS) Test 

- To quantify the distance between the empirical and simualted degree distribution, we can use the KS statistic, defined as 
$$D = \sup_x |E(x) - S(x)|$$
Here, $E(x)$ is the empirical CDF and $S(x)$ is the CDF for the simulated distribution. We test, 
$$\mathcal{H}_0 : E(x) = S(x), \forall x\ \ \ \ \ \ \ \ \mathcal{H}_1:E(x) \neq S(x)$$
To reject $\mathcal{H}_0$, we need about $D > 0.025$. 
- KS test shows that, $D^{out} \approx 0.107$ and $D^{in} \approx 0.051$ for the out and in-degree respectively

$\implies$ **Not a good fit**

## Joint In-Out Degree Distribution

```{r, echo=FALSE, warning=FALSE, message = FALSE, fig.align="center",fig.height=3, fig.width=4, fig.cap = "In vs. Out Degree of the Real and Simualted Network"}
bit_edge <- read.csv("/Users/MacUser/Desktop/Network/Final Project/soc-sign-bitcoinotc.csv", header = FALSE)
bit_edge <- bit_edge[,-4]
#All edges
in_degree_real <- colSums(bit_adj)
out_degree_real <- rowSums(bit_adj)
in_degree_sim <- colSums(sim_bit$adj)
out_degree_sim <- rowSums(sim_bit$adj)

#First 10,000(or something else) edges
test <- Partition(matrix = bit_edge, K = 4)
test0 <- test[1]
test0 <- graph.data.frame(test0, directed=TRUE)
test0 <- matrix(as_adjacency_matrix(test0), nrow = dim(as_adjacency_matrix(test0))[1], 
                ncol = dim(as_adjacency_matrix(test0))[1])
real0_in <- colSums(test0); real0_out <- rowSums(test0)

test_sim <- Partition(matrix = sim_bit$edge_list, K = 4)
test0_sim <- graph.data.frame(test_sim[1], directed=TRUE)
test0_sim <- matrix(as_adjacency_matrix(test0_sim), nrow = dim(as_adjacency_matrix(test0_sim))[1],
                ncol = dim(as_adjacency_matrix(test0_sim))[1])
sim0_in <- colSums(test0_sim); sim0_out <- rowSums(test0_sim)

par(mfrow=c(1,2)) 
par(mar = c(2,2,2,2))
plot(in_degree_real, out_degree_real, log = "xy", col = "red", cex = 0.1, cex.lab = 0.1, main = 
       "Real Network (Log Scale)", xlab = "Log(in-degree)", ylab = "Log(out-degree)", cex.main = 0.6, cex.axis = 0.5)
points(real0_in, real0_out,log = "xy",   pch = 10, cex = 0.1, cex.lab = 0.1, col = "black")
legend("topleft", legend=c("First 10,000 Edges", "All 35,592 Edges"), col = c("gray25", "red"), pch=c(10, 16), cex=0.5, bty = "n")

plot(in_degree_sim, out_degree_sim, log = "xy", col ="blue", cex = 0.1, cex.lab = 0.1,
     main = "Simulated Netowork (Log Scale)", xlab = "Log(in-degree)", ylab = "Log(out-degree)",cex.main = 0.6,cex.axis = 0.5 )
points(sim0_in, sim0_out,log = "xy",   pch = 10, cex = 0.1, cex.lab = 0.1, col = "black")
#points(real1_in, real1_out, log = "xy", pch = 4, cex = 0.2, cex.lab = 0.2, col = "red")
#points(real2_in, real2_out,log = "xy",  pch = 6, cex = 0.2, cex.lab = 0.2, col = "gray69")
legend("topleft", legend=c("First 10,000 Edges", "All 35,592 Edges"), col = c("gray25", "blue"), pch=c(10, 16), cex=0.5, bty = "n")
```

## Joint In-Out Degree Distribution

- Much higher correlation between in and out degree in the real network
    * $\implies$ Using some notion of total degree for the PA mechanism?
    
- High in and out degree correlation early on in the real network
    * $\implies$ Accelerated dynamics? Latent factors (covariates) that dominate the effects of staying longer in the network? 

- Higher concentration of in and out degree in high degree regions for the real data
    * $\implies$ Non-linear attachment?
        - For example, in the Barabasi-Albert model, if the attachment exponent $\alpha > 1$, then we get a winner takes all situation [@Krapivsky2000]
    - Confirms the observation of fatter tails for real data
    
## Heatmap of the Adjacency Matrix

![Heatmap for the real network](/Users/MacUser/Desktop/Network/Final Project/heatmap_real.png)

## Heatmap of the Adjacency Matrix

![Heatmap for the simulated network](/Users/MacUser/Desktop/Network/Final Project/heatmap_sim.png)

## Next Steps

- Clustering Coefficients
- Connectivity
- Dynamics 
- More sample of simulated network (if time allows)

## Reference{.allowframebreaks}
